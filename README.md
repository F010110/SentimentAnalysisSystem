# æƒ…æ„Ÿåˆ†æç³»ç»Ÿ (Sentiment Analysis System)

ä¸€ä¸ªåŸºäº PyTorch å’Œ BERT çš„ Twitter æ–‡æœ¬æƒ…æ„Ÿåˆ†æç³»ç»Ÿï¼Œæ”¯æŒ CPU/GPU è®­ç»ƒï¼Œä¼˜åŒ–äº†äº‘æœåŠ¡å™¨éƒ¨ç½²ã€‚

## ğŸ“Š é¡¹ç›®æ¦‚è§ˆ

### æ•°æ®é›†
- **è®­ç»ƒé›†**: 72,142 æ ·æœ¬ (twitter_training_cleaned.csv)
- **éªŒè¯é›†**: 1,000 æ ·æœ¬ (twitter_validation_cleaned.csv)
- **åˆ†ç±»ç±»åˆ«**: 4 ç±»ï¼ˆIrrelevant, Negative, Neutral, Positiveï¼‰

### æ¨¡å‹æ¶æ„
| æ¨¡å‹ | å‡†ç¡®ç‡ | å¤‡æ³¨ |
|------|--------|------|
| **BERT-base** | ğŸ”„ è®­ç»ƒä¸­ | 110M å‚æ•°ï¼Œå¾®è°ƒç‰ˆæœ¬ |
| SVM | 96.2% | åŸºçº¿æ¨¡å‹ |
| Random Forest | 95.9% | åŸºçº¿æ¨¡å‹ |
| XGBoost | 93.2% | åŸºçº¿æ¨¡å‹ |
| KNN | 93.6% | åŸºçº¿æ¨¡å‹ |
| GRU | ~96% | è‡ªå®šä¹‰ GRU æ¶æ„ |

## ğŸš€ å¿«é€Ÿå¼€å§‹

### å‰ç½®è¦æ±‚
```bash
Python >= 3.8
PyTorch >= 1.9
transformers >= 4.20
pandas, numpy, scikit-learn, matplotlib, seaborn
```

### ç¯å¢ƒé…ç½®

#### é€‰é¡¹ 1: æœ¬åœ° CPU ç¯å¢ƒ
```bash
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu
pip install transformers pandas numpy scikit-learn matplotlib seaborn
```

#### é€‰é¡¹ 2: GPU ç¯å¢ƒï¼ˆCUDA 11.8ï¼‰
```bash
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
pip install transformers pandas numpy scikit-learn matplotlib seaborn
```

#### é€‰é¡¹ 3: ä½¿ç”¨ conda
```bash
conda create -n sentiment-analysis python=3.10
conda activate sentiment-analysis
conda install pytorch pytorch-cuda=11.8 -c pytorch -c nvidia
pip install transformers pandas scikit-learn matplotlib seaborn
```

## ğŸ“ é¡¹ç›®ç»“æ„

```
SentimentAnalysisSystem/
â”œâ”€â”€ README.md                           # æœ¬æ–‡ä»¶
â”‚
â”œâ”€â”€ ã€BERT æ¨¡å‹ã€‘
â”œâ”€â”€ BERT_main.py                        # BERT è®­ç»ƒä¸»ç¨‹åº
â”œâ”€â”€ BERT_model.py                       # BERT æ¨¡å‹å®šä¹‰å’Œè®­ç»ƒå‡½æ•°
â”œâ”€â”€ BERT_config.py                      # BERT é…ç½®ï¼ˆåœ¨çº¿/ç¦»çº¿æ¨¡å¼ï¼‰
â”œâ”€â”€ download_models.py                  # æ¨¡å‹ä¸‹è½½å·¥å…·
â”œâ”€â”€ check_model.py                      # æ¨¡å‹è¯Šæ–­å·¥å…·
â”‚
â”œâ”€â”€ ã€RNN æ¨¡å‹ã€‘
â”œâ”€â”€ RNN_main.py                         # RNN è®­ç»ƒä¸»ç¨‹åº
â”œâ”€â”€ RNN_model.py                        # RNN æ¨¡å‹å®šä¹‰
â”œâ”€â”€ text_process.py                     # æ•°æ®å¤„ç†å’Œé¢„å¤„ç†
â”‚
â”œâ”€â”€ ã€æ•°æ®æ–‡ä»¶ã€‘
â”œâ”€â”€ dataset/
â”‚   â”œâ”€â”€ twitter_training.csv            # åŸå§‹è®­ç»ƒé›†
â”‚   â”œâ”€â”€ twitter_training_cleaned.csv    # æ¸…æ´—åçš„è®­ç»ƒé›†
â”‚   â”œâ”€â”€ twitter_validation.csv          # åŸå§‹éªŒè¯é›†
â”‚   â””â”€â”€ twitter_validation_cleaned.csv  # æ¸…æ´—åçš„éªŒè¯é›†
â”‚
â”œâ”€â”€ ã€æ¨¡å‹æ–‡ä»¶ã€‘(è¿è¡Œåç”Ÿæˆ)
â”œâ”€â”€ models/                             # HuggingFace æ¨¡å‹ç¼“å­˜
â”‚   â””â”€â”€ bert-base-uncased/
â”‚       â”œâ”€â”€ config.json
â”‚       â”œâ”€â”€ model.safetensors
â”‚       â”œâ”€â”€ tokenizer.json
â”‚       â””â”€â”€ ...
â”‚
â”œâ”€â”€ ã€è¾“å‡ºæ–‡ä»¶ã€‘(è®­ç»ƒåç”Ÿæˆ)
â”œâ”€â”€ bert_model_final.pt                 # BERT æœ€ç»ˆæ¨¡å‹
â”œâ”€â”€ bert_model_best.pt                  # BERT æœ€ä½³æ¨¡å‹
â”œâ”€â”€ bert_training_history.png           # è®­ç»ƒå†å²æ›²çº¿
â”œâ”€â”€ bert_confusion_matrix.png           # æ··æ·†çŸ©é˜µ
â”œâ”€â”€ sentiment_model.pth                 # RNN æ¨¡å‹æ£€æŸ¥ç‚¹
â”œâ”€â”€ predictions.csv                     # é¢„æµ‹ç»“æœ
â””â”€â”€ training_history.png                # RNN è®­ç»ƒæ›²çº¿
```

## ğŸ“‹ é’ˆå¯¹BERTçš„å®Œæ•´ä½¿ç”¨æµç¨‹ï¼ˆå…¶ä»–æ¨¡å‹ç›´æ¥è¿è¡Œå³å¯ï¼‰

### æ­¥éª¤ 1: ä¸‹è½½æ¨¡å‹ï¼ˆæœ¬åœ°æ‰§è¡Œï¼‰

å¦‚æœä½ çš„æœåŠ¡å™¨**æ— æ³•è®¿é—® HuggingFace**ï¼Œéœ€è¦å…ˆåœ¨æœ¬åœ°ä¸‹è½½æ¨¡å‹ï¼Œç„¶åä¸Šä¼ åˆ°æœåŠ¡å™¨ã€‚

#### 1.1 æœ¬åœ°ä¸‹è½½æ¨¡å‹
åœ¨ä½ çš„**æœ¬åœ°æœºå™¨**è¿è¡Œï¼ˆéœ€è¦ç½‘ç»œè¿æ¥ï¼‰ï¼š
```bash
python download_models.py
```

è¾“å‡ºç¤ºä¾‹ï¼š
```
============================================================
HuggingFace æ¨¡å‹ç¦»çº¿ä¸‹è½½å·¥å…· v2
============================================================
æ¨¡å‹ä¿å­˜ç›®å½•: /path/to/models

âœ… ç½‘ç»œè¿æ¥æ­£å¸¸

============================================================
æ­£åœ¨ä¸‹è½½: bert-base-uncased
============================================================
...
âœ… åˆ†è¯å™¨å·²ä¸‹è½½
âœ… æ¨¡å‹å·²ä¸‹è½½
ä¿å­˜åˆ°æœ¬åœ°ç›®å½•: ./models/bert-base-uncased
âœ… æ–‡ä»¶å·²ä¿å­˜
ğŸ“¦ æ€»å¤§å°: 417.92 MB

å·²ä¿å­˜çš„æ–‡ä»¶:
  âœ“ config.json (0.01 MB)
  âœ“ model.safetensors (417.66 MB)
  âœ“ tokenizer.json (0.68 MB)
  ...
```

#### 1.2 éªŒè¯æ¨¡å‹å®Œæ•´æ€§
```bash
python check_model.py
```

è¾“å‡ºåº”è¯¥æ˜¾ç¤ºï¼š
```
âœ… æ¨¡å‹å·²å­˜åœ¨ (6 ä¸ªæ–‡ä»¶, 417.92 MB)
âœ… åˆ†è¯å™¨åŠ è½½æˆåŠŸ!
âœ… æ¨¡å‹åŠ è½½æˆåŠŸ!
âœ… æ‰€æœ‰æ£€æŸ¥éƒ½é€šè¿‡äº†ï¼
```

### æ­¥éª¤ 2: ä¸Šä¼ åˆ°æœåŠ¡å™¨

å°†ä»¥ä¸‹å†…å®¹ä¸Šä¼ åˆ°äº‘æœåŠ¡å™¨ï¼š
```
SentimentAnalysisSystem/
â”œâ”€â”€ BERT_main.py
â”œâ”€â”€ BERT_model.py
â”œâ”€â”€ BERT_config.py
â”œâ”€â”€ text_process.py
â”œâ”€â”€ dataset/
â”‚   â””â”€â”€ twitter_training_cleaned.csv
â”‚   â””â”€â”€ twitter_validation_cleaned.csv
â””â”€â”€ models/                    â† å…³é”®ï¼šåŒ…å«ä¸‹è½½çš„æ¨¡å‹
    â””â”€â”€ bert-base-uncased/
        â”œâ”€â”€ config.json
        â”œâ”€â”€ model.safetensors
        â”œâ”€â”€ tokenizer.json
        â””â”€â”€ ...
```

### æ­¥éª¤ 3: æœåŠ¡å™¨é…ç½®

ç™»å½•åˆ°äº‘æœåŠ¡å™¨åï¼Œç¼–è¾‘ `BERT_config.py`ï¼š

```python
# BERT_config.py

# é€‰æ‹©æ¨¡å¼
MODE = 'offline'  # âœ… ä½¿ç”¨æœ¬åœ°æ¨¡å‹ï¼ˆæ¨èï¼‰
# MODE = 'online'   # å¦‚æœæœåŠ¡å™¨èƒ½è®¿é—® HuggingFaceï¼Œå¯ä»¥æ”¹ä¸ºåœ¨çº¿

# æœ¬åœ°æ¨¡å‹é…ç½®
LOCAL_MODELS_DIR = './models'  # ç›¸å¯¹è·¯å¾„æˆ–ç»å¯¹è·¯å¾„
LOCAL_MODEL_NAME = 'bert-base-uncased'
```

### æ­¥éª¤ 4: è®­ç»ƒæ¨¡å‹

åœ¨æœåŠ¡å™¨ä¸Šè¿è¡Œè®­ç»ƒï¼š

#### 4.1 å¿«é€Ÿæµ‹è¯•ï¼ˆéªŒè¯ä»£ç å¯ç”¨ï¼‰
```bash
# ä¿®æ”¹ BERT_main.py ä¸­çš„ NUM_EPOCHS = 1 è¿›è¡Œå¿«é€Ÿæµ‹è¯•
python BERT_main.py
```

#### 4.2 å®Œæ•´è®­ç»ƒ
```bash
# æ¢å¤ BERT_main.py ä¸­çš„ NUM_EPOCHS = 5
python BERT_main.py
```

è®­ç»ƒè¾“å‡ºç¤ºä¾‹ï¼š
```
============================================================
BERT æƒ…æ„Ÿåˆ†ææ¨¡å‹ - Kaggle GPU ä¼˜åŒ–ç‰ˆæœ¬
============================================================

============================================================
BERT æ¨¡å‹é…ç½®
============================================================
æ¨¡å¼: offline
æœ¬åœ°æ¨¡å‹ç›®å½•: /root/Workspace/SentimentAnalysisSystem/models/bert-base-uncased
âœ… æ¨¡å‹å·²å­˜åœ¨ (6 ä¸ªæ–‡ä»¶, 417.92 MB)
============================================================

æ­¥éª¤ 1: åŠ è½½å’Œé¢„å¤„ç†æ•°æ®
============================================================
è®­ç»ƒé›†å¤§å°: 72142
éªŒè¯é›†å¤§å°: 1000
æ£€æµ‹åˆ° 4 ä¸ªç±»åˆ«:
æ ‡ç­¾æ˜ å°„: {0: 'Irrelevant', 1: 'Negative', 2: 'Neutral', 3: 'Positive'}

æ­¥éª¤ 2: åˆå§‹åŒ–åˆ†è¯å™¨
============================================================
åŠ è½½åˆ†è¯å™¨: /root/Workspace/SentimentAnalysisSystem/models/bert-base-uncased
ä»æœ¬åœ°åŠ è½½åˆ†è¯å™¨...

...

Epoch 1/5
Epoch [1/5] Batch [50/564] Loss: 0.5621
Epoch [1/5] Batch [100/564] Loss: 0.4532
...

è®­ç»ƒæŸå¤±: 0.2145 | è®­ç»ƒå‡†ç¡®ç‡: 0.9234
éªŒè¯æŸå¤±: 0.2856 | éªŒè¯å‡†ç¡®ç‡: 0.9156
```

### æ­¥éª¤ 5: æŸ¥çœ‹ç»“æœ

è®­ç»ƒå®Œæˆåä¼šç”Ÿæˆä»¥ä¸‹æ–‡ä»¶ï¼š
- `bert_training_history.png` - è®­ç»ƒæ›²çº¿
- `bert_confusion_matrix.png` - æ··æ·†çŸ©é˜µ
- `bert_model_final.pt` - æœ€ç»ˆæ¨¡å‹
- æ§åˆ¶å°è¾“å‡ºè¯¦ç»†çš„åˆ†ç±»æŠ¥å‘Š

## ğŸ¯ å…³é”®é…ç½®å‚æ•°

ç¼–è¾‘ `BERT_main.py` ä¸­çš„ `main()` å‡½æ•°ï¼š

```python
# æ¨¡å‹é…ç½® - RTX 4090 ä¼˜åŒ–ç‰ˆæœ¬ (24GB VRAM)
MODEL_NAME = 'bert-base-uncased'           # æ¨¡å‹é€‰æ‹©
MAX_LENGTH = 128                           # æœ€å¤§åºåˆ—é•¿åº¦
NUM_CLASSES = 4                            # åˆ†ç±»ç±»åˆ«æ•°
BATCH_SIZE = 128                           # æ‰¹å¤§å°ï¼ˆRTX 4090ï¼‰
LEARNING_RATE = 2e-5                       # å­¦ä¹ ç‡
NUM_EPOCHS = 5                             # è®­ç»ƒè½®æ•°
WARMUP_STEPS = 300                         # é¢„çƒ­æ­¥æ•°
GRADIENT_ACCUMULATION_STEPS = 2            # æ¢¯åº¦ç´¯ç§¯
ENABLE_FP16 = True                         # æ··åˆç²¾åº¦
NUM_WORKERS = 4                            # æ•°æ®åŠ è½½è¿›ç¨‹æ•°
```

### æ ¹æ®ç¡¬ä»¶è°ƒæ•´ Batch Size

| ç¡¬ä»¶ | æ¨è Batch Size | æ˜¾å­˜å ç”¨ |
|------|-----------------|---------|
| RTX 4090 (24GB) | 128 | ~8GB |
| RTX 3090 (24GB) | 96-128 | ~18GB |
| RTX 3080 (10GB) | 32-64 | ~8GB |
| Tesla V100 (16GB) | 64-96 | ~12GB |
| Kaggle (16GB) | 32-64 | ~10GB |
| CPU | 8-16 | å†…å­˜ |

## ğŸ“Š æ€§èƒ½å¯¹æ¯”

### ç¡¬ä»¶æ€§èƒ½

| è®¾å¤‡ | æ¯ä¸ª Epoch | 5 Epochs æ€»æ—¶é—´ |
|------|-----------|-----------------|
| **RTX 4090** (BS=128) | ~0.5 åˆ†é’Ÿ | **~2.5 åˆ†é’Ÿ** âš¡ |
| RTX 3090 (BS=96) | ~1 åˆ†é’Ÿ | ~5 åˆ†é’Ÿ |
| RTX 3080 (BS=64) | ~2 åˆ†é’Ÿ | ~10 åˆ†é’Ÿ |
| Tesla V100 (BS=64) | ~1.5 åˆ†é’Ÿ | ~7.5 åˆ†é’Ÿ |
| Kaggle GPU (BS=32) | ~3 åˆ†é’Ÿ | ~15 åˆ†é’Ÿ |
| CPU | ~30 åˆ†é’Ÿ | ~150 åˆ†é’Ÿ |

### æ¨¡å‹æ€§èƒ½ï¼ˆå‚è€ƒï¼‰

- **BERT-base**: å‡†ç¡®ç‡ ~92-93% (å¾®è°ƒå)
- **è’¸é¦ BERT**: å‡†ç¡®ç‡ ~90-91% (æ›´è½»é‡)
- **RoBERTa-base**: å‡†ç¡®ç‡ ~93-94% (æ›´å¼º)

## ğŸ”§ æ•…éšœæ’æŸ¥

### é—®é¢˜ 1: æ¨¡å‹åŠ è½½å¤±è´¥
```
FileNotFoundError: æœ¬åœ°æ¨¡å‹è·¯å¾„ä¸å­˜åœ¨
```
**è§£å†³æ–¹æ¡ˆ:**
1. ç¡®è®¤ `models/bert-base-uncased/` æ–‡ä»¶å¤¹å­˜åœ¨
2. è¿è¡Œ `python check_model.py` æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
3. ç¡®è®¤ `BERT_config.py` ä¸­ `MODE = 'offline'`

### é—®é¢˜ 2: HuggingFace è¶…æ—¶
```
ReadTimeoutError: HTTPSConnectionPool timeout
```
**è§£å†³æ–¹æ¡ˆ:**
1. ä½¿ç”¨ç¦»çº¿æ¨¡å¼ï¼ˆåœ¨æœ¬åœ°ä¸‹è½½åä¸Šä¼ ï¼‰
2. æˆ–å¢åŠ è¶…æ—¶æ—¶é—´ï¼šç¼–è¾‘ `BERT_config.py` ä¸­çš„ `HF_TIMEOUT`

### é—®é¢˜ 3: æ˜¾å­˜ä¸è¶³
```
CUDA out of memory
```
**è§£å†³æ–¹æ¡ˆ:**
1. å‡å°‘ `BATCH_SIZE`ï¼ˆå¦‚ä» 128 æ”¹ä¸º 64ï¼‰
2. å‡å°‘ `MAX_LENGTH`ï¼ˆå¦‚ä» 128 æ”¹ä¸º 96ï¼‰
3. è®¾ç½® `GRADIENT_ACCUMULATION_STEPS = 4`

### é—®é¢˜ 4: æ•°æ®åŠ è½½ç¼“æ…¢
**è§£å†³æ–¹æ¡ˆ:**
1. å¢åŠ  `NUM_WORKERS`ï¼ˆå¦‚ä» 4 æ”¹ä¸º 8ï¼‰
2. ç¡®ä¿ä½¿ç”¨ `pin_memory=True`

## ğŸ’¾ æ•°æ®æ ¼å¼

### è®­ç»ƒ/éªŒè¯æ•°æ®
å¿…é¡»åŒ…å«ä»¥ä¸‹åˆ—ï¼š
- `processed_text` (æˆ– `text`): å¤„ç†åçš„æ–‡æœ¬
- `attitude`: æƒ…æ„Ÿæ ‡ç­¾ï¼ˆæ”¯æŒå­—ç¬¦ä¸²æˆ–æ•°å­—ï¼‰

ç¤ºä¾‹ï¼š
```csv
processed_text,attitude
"this movie is great",Positive
"i hate this",Negative
"it is okay",Neutral
"not relevant",Irrelevant
```

## ğŸŒ åœ¨çº¿æ¨¡å¼é…ç½®

å¦‚æœä½ çš„æœåŠ¡å™¨**å¯ä»¥è®¿é—® HuggingFace**ï¼Œå¯ä»¥ä½¿ç”¨åœ¨çº¿æ¨¡å¼ï¼š

```python
# BERT_config.py
MODE = 'online'  # æ”¹ä¸ºåœ¨çº¿æ¨¡å¼

# HuggingFace æ¨¡å‹é€‰é¡¹
HUGGINGFACE_MODEL_NAME = 'bert-base-uncased'
# å…¶ä»–é€‰é¡¹:
# 'distilbert-base-uncased' - è½»é‡ç‰ˆï¼ˆå‚æ•°å°‘ 40%ï¼‰
# 'roberta-base' - æ›´å¼ºç‰ˆæœ¬
# 'albert-base-v2' - è½»é‡ç‰ˆ
```

åœ¨çº¿æ¨¡å¼ä¼šè‡ªåŠ¨ä» HuggingFace ä¸‹è½½ï¼Œé¦–æ¬¡è¿è¡Œéœ€è¦ç½‘ç»œã€‚

## ğŸ“š ç›¸å…³èµ„æº

- [BERT è®ºæ–‡](https://arxiv.org/abs/1810.04805)
- [HuggingFace Transformers](https://huggingface.co/docs/transformers/)
- [PyTorch æ–‡æ¡£](https://pytorch.org/docs/)

## âœ¨ ä¼˜åŒ–æŠ€æœ¯

æœ¬æ¨¡å‹ï¼ˆBERTï¼‰ä½¿ç”¨ä»¥ä¸‹ä¼˜åŒ–æŠ€æœ¯ï¼š

- **æ··åˆç²¾åº¦è®­ç»ƒ (FP16)**: åŠ é€Ÿ 20-30%ï¼ŒèŠ‚çœ 50% æ˜¾å­˜
- **æ¢¯åº¦ç´¯ç§¯**: æœ‰æ•ˆå¢å¤§ Batch Sizeï¼Œä¸é¢å¤–å ç”¨æ˜¾å­˜
- **æ¢¯åº¦è£å‰ª**: é˜²æ­¢æ¢¯åº¦çˆ†ç‚¸
- **é¢„çƒ­ (Warmup)**: ç¨³å®šå­¦ä¹ ç‡å˜åŒ–
- **å¤šè¿›ç¨‹æ•°æ®åŠ è½½**: å……åˆ†åˆ©ç”¨ CPU
- **å†…å­˜é”å®š (Pin Memory)**: åŠ å¿« CPU-GPU æ•°æ®ä¼ è¾“

## ğŸ“„ è®¸å¯è¯

MIT License

---

**æœ€åæ›´æ–°**: 2025-12-05  
**ç‰ˆæœ¬**: 2.0 (BERT + RNN)

