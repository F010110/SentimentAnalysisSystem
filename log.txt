背景：
    在人工智能导论课发布作业之前，我已经做了一个半成品的情感分析系统，基于RNN（实际上是GRU）。
    为什么说是半成品呢？因为GRU的准确率只有92.9%，而基准模型中的SVM、随机森林、
    XGBoost、KNN的准确率都比这高，其中SVM的准确率高达96.2% 。
    现在我先要对GRU调参，或者找出基准模型准确率普遍高的原因。





问题1：怎么改进GRU？

AI建议：
    查看混淆矩阵：RNN在哪几类上表现差？
    检查词表覆盖率：有多少测试集词被映射为<UNK>？
    对比特征：用TF-IDF特征训练一个简单的NN，看是否能接近SVM效果
    学习曲线：RNN是否过拟合/欠拟合？
    
    建议先调整清洗策略和使用预训练词向量，这两个改动最容易实施且通常效果最明显。

我现在尝试学VScode远程连接实例……

和deepseek斗智斗勇半天终于学会了。
deepseek以为我很聪明，没要考虑到我在尝试远程连接之前没有启动实例的可能…………
而我之所以在尝试远程连接之前没有启动实例，仅仅是为了节省几分钱。

我微调了数据清洗策略（再negation_words中补充程度副词，并确保单字母词i、a、u不被移除），
又大幅调整模型参数：
    EMBED_DIM = 300        # 增加嵌入维度（原128）
    HIDDEN_DIM = 256       # 增加隐藏层维度（原64）
    N_LAYERS = 3           # 增加层数（原2）
    DROPOUT = 0.5          # 增加dropout（原0.3）
    BATCH_SIZE = 64        # 增加批大小（原32）
    LEARNING_RATE = 0.0005 # 降低学习率（原0.001）

现在GRU的准确率达到95.5%，但离SVM还有差距。

AI建议：
    先试试类权重调整（最快，可能直接提升0.2-0.3%）
    修改优化器为AdamW + 微调学习率
    改进GRU的forward方法（加入池化）
    添加简单的注意力机制
    使用加权采样

我先计算类别权重以解决解决潜在的不平衡问题，修改criterion。
然后把optimizer从Adam改为AdamW，并减小weight_decay。
然后改进GRU隐藏状态的使用，引入了平均池化和最大池化，再把结果concat。
    这样得再把self.fc的维度改一下。这Deepseek竟然不提醒我。还好我不傻。我让copilot给我改。
    还得是copilot中的claude sonnet靠谱。一下就改对。
然后我再修改dropout策略…………我怎么没看懂deepseek让我干什么…………算了，不改了。

跑一个看看…………这次Train Acc上升的很快啊！

但是测试集准确率还是只有95.7%，而Train Acc达到97.95%，看起来是有点过拟合。
再问问AI…………

AI建议：
    1. 降低模型复杂度
    2. 添加早停机制
    3. 使用标签平滑

先试试 降低模型复杂度：
    EMBED_DIM = 200        # 减少嵌入维度（原300）
    HIDDEN_DIM = 128       # 减少隐藏层维度（原256）
    N_LAYERS = 2           # 减少层数（原3）
    DROPOUT = 0.6          # 增加dropout（原0.5）

现在准确率达到96.0%，我再减少一些epochs。

还是96.0%，我再随便调调参数。

把N_LAYERS改到4，准确率最高的一次达到96.8%！
但这也只是昙花一现。
同样的参数跑出来的模型性能也有差距，应该是因为dropout是随机的。

后面再也没有调出比96.8更高的了。

